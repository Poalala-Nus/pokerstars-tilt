{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5c3b93d",
      "metadata": {
        "id": "a5c3b93d"
      },
      "source": [
        "# PokerStars ‚Äî Data Cleaning (version clean √† rendre)\n",
        "\n",
        "Ce notebook reconstruit **uniquement si besoin** les artefacts de cleaning utilis√©s ensuite par l'EDA et le Machine Learning (ML) :\n",
        "\n",
        "1. **Raw PHH/PHHS ‚Üí Parquet**  \n",
        "   - `hands_parquet/`  \n",
        "   - `player_hands_parquet/`  (filtrage ~20% joueurs via hash)\n",
        "\n",
        "2. **Timeline (DuckDB) ‚Üí Parquet**  \n",
        "   - `timeline_parquet/` (partitionn√© par `stake_label` et `player_bucket`)\n",
        "\n",
        "3. **√âchantillon √©quilibr√©** (ex: 300 joueurs / stake)  \n",
        "   - `sample_players_balanced.csv`\n",
        "\n",
        "4. **Exports bulk** (ex: 200 mains / joueur)  \n",
        "   - `player_transcripts_bulk_300p_200h/`\n",
        "\n",
        "5. **Structuration TXT ‚Üí Parquet**  \n",
        "   - `_structured/hands_parquet/`  \n",
        "   - `_structured/actions_parquet/`\n",
        "\n",
        "## Important (anti-duplication dans Drive)\n",
        "Par d√©faut, ce notebook est **idempotent** :  \n",
        "- si un dossier de sortie existe d√©j√† et contient des fichiers, l‚Äô√©tape correspondante est **skip** ;  \n",
        "- pour forcer une reconstruction, mets le flag `FORCE_... = True` au d√©but de l‚Äô√©tape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "be05b9c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be05b9c8",
        "outputId": "d7e8ee83-c4df-4abd-e1d4-0fb2fb5dd047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ OUT_ROOT_FULL: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Drive (Colab) ---\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# --- Imports ---\n",
        "import os, glob, re, json, hashlib, shutil, random, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Paths (Drive) ---\n",
        "OUT_ROOT_FULL = \"/content/drive/MyDrive/pokerstars_clean/follow_20pct_full\"\n",
        "\n",
        "HANDS_DIR_FULL = f\"{OUT_ROOT_FULL}/hands_parquet\"\n",
        "PH_DIR_FULL    = f\"{OUT_ROOT_FULL}/player_hands_parquet\"\n",
        "TIMELINE_DIR_FULL = f\"{OUT_ROOT_FULL}/timeline_parquet\"\n",
        "\n",
        "EXPORT_BULK_DIR = f\"{OUT_ROOT_FULL}/player_transcripts_bulk_300p_200h\"   # 300 players / stake, 200 hands / player\n",
        "STRUCT_DIR      = os.path.join(EXPORT_BULK_DIR, \"_structured\")\n",
        "STRUCT_HANDS_DIR = os.path.join(STRUCT_DIR, \"hands_parquet\")\n",
        "STRUCT_ACT_DIR   = os.path.join(STRUCT_DIR, \"actions_parquet\")\n",
        "\n",
        "SAMPLE_CSV = os.path.join(EXPORT_BULK_DIR, \"sample_players_balanced.csv\")\n",
        "\n",
        "def dir_has_files(p: str) -> bool:\n",
        "    return os.path.isdir(p) and any(os.scandir(p))\n",
        "\n",
        "print(\"‚úÖ OUT_ROOT_FULL:\", OUT_ROOT_FULL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "87e504b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87e504b3",
        "outputId": "fa70472b-538e-4a73-83ac-45ca5c108913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stake   25 | exists=True | path=/content/drive/MyDrive/projet adv data/0.25\n",
            "Stake   50 | exists=True | path=/content/drive/MyDrive/projet adv data/0.5\n",
            "Stake  200 | exists=True | path=/content/drive/MyDrive/projet adv data/2\n",
            "Stake  400 | exists=True | path=/content/drive/MyDrive/projet adv data/4\n",
            "Stake  600 | exists=True | path=/content/drive/MyDrive/projet adv data/6\n",
            "Stake 1000 | exists=True | path=/content/drive/MyDrive/projet adv data/10\n"
          ]
        }
      ],
      "source": [
        "# --- Raw PHH/PHHS directories (Drive) ---\n",
        "RAW_DIRS = {\n",
        "    25:   \"/content/drive/MyDrive/projet adv data/0.25\",\n",
        "    50:   \"/content/drive/MyDrive/projet adv data/0.5\",\n",
        "    200:  \"/content/drive/MyDrive/projet adv data/2\",\n",
        "    400:  \"/content/drive/MyDrive/projet adv data/4\",\n",
        "    600:  \"/content/drive/MyDrive/projet adv data/6\",\n",
        "    1000: \"/content/drive/MyDrive/projet adv data/10\",\n",
        "}\n",
        "\n",
        "# quick sanity check (does not scan recursively)\n",
        "for stake, root in RAW_DIRS.items():\n",
        "    print(f\"Stake {stake:>4} | exists={os.path.exists(root)} | path={root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb3f7cd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb3f7cd0",
        "outputId": "cf7036d1-1ae6-4226-bdf2-5fc5fa6d349a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Helpers charg√©s (KEEP_PCT=20, N_BUCKETS=256)\n"
          ]
        }
      ],
      "source": [
        "import re, glob, hashlib, json\n",
        "import pandas as pd\n",
        "\n",
        "# R√©glages\n",
        "KEEP_PCT = 20          # garder ~20% des joueurs\n",
        "N_BUCKETS = 256        # partition joueurs\n",
        "FLUSH_HANDS = 20_000   # √©criture mains (tu peux augmenter apr√®s)\n",
        "FLUSH_PH    = 100_000  # √©criture player-hands (tu peux augmenter apr√®s)\n",
        "\n",
        "SEC_RE   = re.compile(r'^\\[(\\d+)\\]\\s*$', re.MULTILINE)\n",
        "TABLE_RE = re.compile(r'table\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']')\n",
        "\n",
        "def md5_int(s: str) -> int:\n",
        "    return int(hashlib.md5(s.encode(\"utf-8\")).hexdigest()[:8], 16)\n",
        "\n",
        "def keep_player(pid: str, keep_pct: int = KEEP_PCT) -> bool:\n",
        "    return (md5_int(pid) % 100) < keep_pct\n",
        "\n",
        "def player_bucket(pid: str, n_buckets: int = N_BUCKETS) -> int:\n",
        "    return md5_int(pid) % n_buckets\n",
        "\n",
        "def iter_sections(text: str):\n",
        "    ms = list(SEC_RE.finditer(text))\n",
        "    if not ms:\n",
        "        return\n",
        "    starts = [m.start() for m in ms] + [len(text)]\n",
        "    ids = [m.group(1) for m in ms]\n",
        "    for i, sec_no in enumerate(ids):\n",
        "        yield int(sec_no), text[starts[i]:starts[i+1]]\n",
        "\n",
        "def get_str(pat: str, s: str):\n",
        "    m = re.search(pat, s)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def get_list_numbers(pat: str, s: str):\n",
        "    m = re.search(pat, s, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        return []\n",
        "    return [float(x) for x in re.findall(r\"[0-9]+\\.[0-9]+|[0-9]+\", m.group(1))]\n",
        "\n",
        "def get_list_strings(pat: str, s: str):\n",
        "    m = re.search(pat, s, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        return []\n",
        "    return re.findall(r\"'([^']+)'\", m.group(1))\n",
        "\n",
        "def get_table_id(sec: str):\n",
        "    m = TABLE_RE.search(sec)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def split_actions(actions):\n",
        "    streets = {\"preflop\": [], \"flop\": [], \"turn\": [], \"river\": [], \"showdown\": []}\n",
        "    board   = {\"flop\": None, \"turn\": None, \"river\": None}\n",
        "    current = \"preflop\"\n",
        "    for a in actions:\n",
        "        if a.startswith(\"d dh\"):\n",
        "            continue\n",
        "        if a.startswith(\"d db \"):\n",
        "            cards = a.split(\" \", 2)[2]\n",
        "            if board[\"flop\"] is None:\n",
        "                board[\"flop\"] = cards; current=\"flop\";  continue\n",
        "            if board[\"turn\"] is None:\n",
        "                board[\"turn\"] = cards; current=\"turn\";  continue\n",
        "            if board[\"river\"] is None:\n",
        "                board[\"river\"] = cards; current=\"river\"; continue\n",
        "        if a.startswith(\"p\") and \" sm\" in a:\n",
        "            streets[\"showdown\"].append(a); continue\n",
        "        streets[current].append(a)\n",
        "    return streets, board\n",
        "\n",
        "def player_token(a: str):\n",
        "    m = re.match(r\"p(\\d+)\\s+(.*)\", a)\n",
        "    return (int(m.group(1)), m.group(2).strip()) if m else (None, a)\n",
        "\n",
        "def position_labels(n: int):\n",
        "    if n<=0: return []\n",
        "    if n==1: return [\"UTG\"]\n",
        "    if n==2: return [\"SB\",\"BB\"]\n",
        "    if n==3: return [\"BTN\",\"SB\",\"BB\"]\n",
        "    utg = max(0, n-4)\n",
        "    names=[]\n",
        "    if utg>0:\n",
        "        names.append(\"UTG\")\n",
        "        for i in range(1, utg):\n",
        "            names.append(f\"UTG+{i}\")\n",
        "    names += [\"CO\",\"BTN\",\"SB\",\"BB\"]\n",
        "    return names\n",
        "\n",
        "def infer_positions_from_preflop(actions):\n",
        "    streets, _ = split_actions(actions)\n",
        "    order=[]\n",
        "    for a in streets[\"preflop\"]:\n",
        "        pid,_ = player_token(a)\n",
        "        if pid and pid not in order:\n",
        "            order.append(pid)\n",
        "    pos = position_labels(len(order))\n",
        "    return {pid: pos[i] for i, pid in enumerate(order)}\n",
        "\n",
        "print(\"‚úÖ Helpers charg√©s (KEEP_PCT=20, N_BUCKETS=256)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dcb530ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcb530ff",
        "outputId": "aa523d08-9de9-4910-c9d6-91c00d6aa1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≠Ô∏è  STEP 1 skipped: hands_parquet + player_hands_parquet d√©j√† pr√©sents.\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# STEP 1 ‚Äî Raw PHH/PHHS -> Parquet (hands + player_hands)\n",
        "# =========================\n",
        "\n",
        "FORCE_REBUILD_HANDS = False  # <- mets True si tu veux √©craser l'existant\n",
        "\n",
        "# Output dirs\n",
        "os.makedirs(HANDS_DIR_FULL, exist_ok=True)\n",
        "os.makedirs(PH_DIR_FULL, exist_ok=True)\n",
        "\n",
        "if dir_has_files(HANDS_DIR_FULL) and dir_has_files(PH_DIR_FULL) and not FORCE_REBUILD_HANDS:\n",
        "    print(\"‚è≠Ô∏è  STEP 1 skipped: hands_parquet + player_hands_parquet d√©j√† pr√©sents.\")\n",
        "else:\n",
        "    if FORCE_REBUILD_HANDS:\n",
        "        print(\"‚ö†Ô∏è FORCE_REBUILD_HANDS=True -> suppression des anciens dossiers de sortie...\")\n",
        "        if os.path.exists(HANDS_DIR_FULL):\n",
        "            shutil.rmtree(HANDS_DIR_FULL)\n",
        "        if os.path.exists(PH_DIR_FULL):\n",
        "            shutil.rmtree(PH_DIR_FULL)\n",
        "        os.makedirs(HANDS_DIR_FULL, exist_ok=True)\n",
        "        os.makedirs(PH_DIR_FULL, exist_ok=True)\n",
        "\n",
        "    # Buffers\n",
        "    hands_buf = {}   # stake_label -> list(rows)\n",
        "    ph_buf    = {}   # (stake_label, bucket) -> list(rows)\n",
        "    hands_part = 0\n",
        "    ph_part    = 0\n",
        "\n",
        "    def flush_hands(stake_label: int):\n",
        "        global hands_part\n",
        "        rows = hands_buf.get(stake_label, [])\n",
        "        if not rows:\n",
        "            return\n",
        "        df = pd.DataFrame(rows)\n",
        "        out_path = os.path.join(HANDS_DIR_FULL, f\"stake_label={stake_label}\")\n",
        "        os.makedirs(out_path, exist_ok=True)\n",
        "        hands_part += 1\n",
        "        file_path = os.path.join(out_path, f\"hands-part-{hands_part:06d}.parquet\")\n",
        "        df.to_parquet(file_path, index=False)\n",
        "        hands_buf[stake_label] = []\n",
        "\n",
        "    def flush_ph(stake_label: int, bucket_id: int):\n",
        "        global ph_part\n",
        "        key = (stake_label, bucket_id)\n",
        "        rows = ph_buf.get(key, [])\n",
        "        if not rows:\n",
        "            return\n",
        "        df = pd.DataFrame(rows)\n",
        "        out_path = os.path.join(PH_DIR_FULL, f\"stake_label={stake_label}\", f\"player_bucket={bucket_id:03d}\")\n",
        "        os.makedirs(out_path, exist_ok=True)\n",
        "        ph_part += 1\n",
        "        file_path = os.path.join(out_path, f\"ph-part-{ph_part:06d}.parquet\")\n",
        "        df.to_parquet(file_path, index=False)\n",
        "        ph_buf[key] = []\n",
        "\n",
        "    def flush_all():\n",
        "        for s in list(hands_buf.keys()):\n",
        "            flush_hands(s)\n",
        "        for (s, b) in list(ph_buf.keys()):\n",
        "            flush_ph(s, b)\n",
        "\n",
        "    total_files = 0\n",
        "    total_hands_seen = 0\n",
        "    hands_kept = 0\n",
        "    ph_rows_kept = 0\n",
        "\n",
        "    for stake_label, root in RAW_DIRS.items():\n",
        "        paths = list(glob.iglob(os.path.join(root, \"**\", \"*.phh*\"), recursive=True))\n",
        "        paths.sort()\n",
        "        print(f\"\\n=== Stake {stake_label} | fichiers: {len(paths)} ===\")\n",
        "\n",
        "        for path in paths:\n",
        "            total_files += 1\n",
        "\n",
        "            with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                txt = f.read()\n",
        "\n",
        "            for _, sec in iter_sections(txt):\n",
        "                venue = get_str(r\"venue\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]\", sec)\n",
        "                if venue != \"PokerStars\":\n",
        "                    continue\n",
        "\n",
        "                table_id = get_table_id(sec)\n",
        "                ts = get_str(r\"ts\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]\", sec)\n",
        "\n",
        "                sb = get_str(r\"sb\\s*=\\s*([0-9.]+)\", sec)\n",
        "                bb = get_str(r\"bb\\s*=\\s*([0-9.]+)\", sec)\n",
        "\n",
        "                hand_uid = md5_int(f\"{os.path.basename(path)}|{sec[:200]}\")\n",
        "\n",
        "                players = get_list_strings(r\"players\\s*=\\s*\\[(.*?)\\]\", sec)\n",
        "                stacks  = get_list_strings(r\"stacks\\s*=\\s*\\[(.*?)\\]\", sec)\n",
        "                seats   = get_list_strings(r\"seats\\s*=\\s*\\[(.*?)\\]\", sec)\n",
        "                actions = get_list_strings(r\"actions\\s*=\\s*\\[(.*?)\\]\", sec)\n",
        "\n",
        "                n = len(players)\n",
        "                if n == 0 or len(stacks) != n:\n",
        "                    continue\n",
        "\n",
        "                total_hands_seen += 1\n",
        "\n",
        "                kept_mask = [keep_player(pid, KEEP_PCT) for pid in players]\n",
        "                if not any(kept_mask):\n",
        "                    continue\n",
        "\n",
        "                hands_kept += 1\n",
        "                seats = (seats + [None]*n)[:n]\n",
        "                pos_map = infer_positions_from_preflop(actions)\n",
        "\n",
        "                # HAND row (1 par main)\n",
        "                hands_buf.setdefault(stake_label, []).append({\n",
        "                    \"stake_label\": stake_label,\n",
        "                    \"ts\": ts,\n",
        "                    \"hand_uid\": int(hand_uid),\n",
        "                    \"table_id\": table_id,\n",
        "                    \"sb\": float(sb) if sb is not None else None,\n",
        "                    \"bb\": float(bb) if bb is not None else None,\n",
        "                    \"players_json\": json.dumps(players),\n",
        "                    \"starting_stacks_json\": json.dumps([float(x) for x in stacks]),\n",
        "                    \"seats_json\": json.dumps(seats),\n",
        "                    \"actions_json\": json.dumps(actions),\n",
        "                    \"source_file\": os.path.basename(path),\n",
        "                })\n",
        "                if len(hands_buf[stake_label]) >= FLUSH_HANDS:\n",
        "                    flush_hands(stake_label)\n",
        "\n",
        "                # PLAYER_HAND rows (1 par joueur gard√©)\n",
        "                for i, pid in enumerate(players):\n",
        "                    if not kept_mask[i]:\n",
        "                        continue\n",
        "                    ph_rows_kept += 1\n",
        "                    b = md5_int(pid) % N_BUCKETS\n",
        "                    key = (stake_label, b)\n",
        "                    ph_buf.setdefault(key, []).append({\n",
        "                        \"stake_label\": stake_label,\n",
        "                        \"player_bucket\": b,\n",
        "                        \"player_id\": pid,\n",
        "                        \"table_id\": table_id,\n",
        "                        \"hand_uid\": int(hand_uid),\n",
        "                        \"ts\": ts,\n",
        "                        \"seat_idx\": i+1,\n",
        "                        \"pos_label\": pos_map.get(i+1, f\"P{i+1}\"),\n",
        "                        \"starting_stack\": float(stacks[i]),\n",
        "                        \"source_file\": os.path.basename(path),\n",
        "                    })\n",
        "                    if len(ph_buf[key]) >= FLUSH_PH:\n",
        "                        flush_ph(stake_label, b)\n",
        "\n",
        "            if total_files % 50 == 0:\n",
        "                print(f\"‚Ä¶ fichiers {total_files} | mains vues {total_hands_seen} | mains gard√©es {hands_kept} | ph_rows {ph_rows_kept}\")\n",
        "\n",
        "    flush_all()\n",
        "\n",
        "    print(\"\\n‚úÖ STEP 1 termin√©\")\n",
        "    print(\"Total fichiers lus:\", total_files)\n",
        "    print(\"Mains vues:\", total_hands_seen)\n",
        "    print(\"Mains gard√©es (>=1 joueur dans 20%):\", hands_kept)\n",
        "    print(\"Lignes PLAYER_HAND gard√©es:\", ph_rows_kept)\n",
        "    print(\"Sorties:\")\n",
        "    print(\" -\", HANDS_DIR_FULL)\n",
        "    print(\" -\", PH_DIR_FULL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "254dedd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "254dedd7",
        "outputId": "fbd8d87e-0d10-41f3-9710-6b86fa9740fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≠Ô∏è  STEP 2 skipped: timeline_parquet d√©j√† pr√©sent.\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# STEP 2 ‚Äî Build timeline_parquet (DuckDB)\n",
        "# =========================\n",
        "\n",
        "FORCE_REBUILD_TIMELINE = False  # <- True pour √©craser timeline_parquet\n",
        "\n",
        "try:\n",
        "    import duckdb\n",
        "except ImportError:\n",
        "    !pip -q install duckdb\n",
        "    import duckdb\n",
        "\n",
        "os.makedirs(TIMELINE_DIR_FULL, exist_ok=True)\n",
        "\n",
        "if dir_has_files(TIMELINE_DIR_FULL) and not FORCE_REBUILD_TIMELINE:\n",
        "    print(\"‚è≠Ô∏è  STEP 2 skipped: timeline_parquet d√©j√† pr√©sent.\")\n",
        "else:\n",
        "    if FORCE_REBUILD_TIMELINE and os.path.exists(TIMELINE_DIR_FULL):\n",
        "        print(\"‚ö†Ô∏è FORCE_REBUILD_TIMELINE=True -> suppression timeline_parquet existant...\")\n",
        "        shutil.rmtree(TIMELINE_DIR_FULL)\n",
        "        os.makedirs(TIMELINE_DIR_FULL, exist_ok=True)\n",
        "\n",
        "    con = duckdb.connect()\n",
        "    con.execute(\"PRAGMA threads=4;\")\n",
        "    con.execute(\"PRAGMA enable_progress_bar=true;\")\n",
        "\n",
        "    con.execute(f'''\n",
        "    COPY (\n",
        "      WITH base AS (\n",
        "        SELECT\n",
        "          stake_label,\n",
        "          player_bucket,\n",
        "          player_id,\n",
        "          table_id,\n",
        "          hand_uid,\n",
        "          ts,\n",
        "          seat_idx,\n",
        "          pos_label,\n",
        "          starting_stack,\n",
        "          source_file,\n",
        "          ROW_NUMBER() OVER w AS rn\n",
        "        FROM parquet_scan('{PH_DIR_FULL}/**/*.parquet')\n",
        "        WINDOW w AS (\n",
        "          PARTITION BY stake_label, table_id, player_id\n",
        "          ORDER BY ts, hand_uid\n",
        "        )\n",
        "      )\n",
        "      SELECT * FROM base\n",
        "    )\n",
        "    TO '{TIMELINE_DIR_FULL}'\n",
        "    (FORMAT PARQUET, PARTITION_BY (stake_label, player_bucket), COMPRESSION ZSTD);\n",
        "    ''')\n",
        "\n",
        "    print(\"‚úÖ Timeline √©crite dans :\", TIMELINE_DIR_FULL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "23e7702e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23e7702e",
        "outputId": "c3f5ff0d-56a1-44c6-9290-5756128554d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≠Ô∏è  STEP 3 skipped: sample_players_balanced.csv d√©j√† pr√©sent.\n",
            "CSV: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/sample_players_balanced.csv\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# STEP 3 ‚Äî Build sample_players_balanced.csv (300 joueurs / stake)\n",
        "# =========================\n",
        "\n",
        "FORCE_RESAMPLE_PLAYERS = False\n",
        "PLAYERS_PER_STAKE = 300\n",
        "STAKE_LABELS = [25, 50, 200, 400, 600, 1000]\n",
        "\n",
        "try:\n",
        "    import duckdb\n",
        "except ImportError:\n",
        "    !pip -q install duckdb\n",
        "    import duckdb\n",
        "\n",
        "os.makedirs(EXPORT_BULK_DIR, exist_ok=True)\n",
        "\n",
        "if os.path.exists(SAMPLE_CSV) and (os.path.getsize(SAMPLE_CSV) > 0) and not FORCE_RESAMPLE_PLAYERS:\n",
        "    print(\"‚è≠Ô∏è  STEP 3 skipped: sample_players_balanced.csv d√©j√† pr√©sent.\")\n",
        "    print(\"CSV:\", SAMPLE_CSV)\n",
        "else:\n",
        "    con = duckdb.connect()\n",
        "    con.execute(\"PRAGMA threads=4;\")\n",
        "    con.execute(\"PRAGMA enable_progress_bar=true;\")\n",
        "\n",
        "    df_samples = con.execute(f'''\n",
        "    WITH players AS (\n",
        "        SELECT stake_label, player_id\n",
        "        FROM parquet_scan('{TIMELINE_DIR_FULL}/**/*.parquet')\n",
        "        GROUP BY stake_label, player_id\n",
        "    ),\n",
        "    ranked AS (\n",
        "        SELECT\n",
        "            stake_label,\n",
        "            player_id,\n",
        "            ROW_NUMBER() OVER (PARTITION BY stake_label ORDER BY md5(player_id)) AS rn\n",
        "        FROM players\n",
        "        WHERE stake_label IN ({\",\".join(map(str, STAKE_LABELS))})\n",
        "    )\n",
        "    SELECT stake_label, player_id\n",
        "    FROM ranked\n",
        "    WHERE rn <= {PLAYERS_PER_STAKE}\n",
        "    ORDER BY stake_label, rn\n",
        "    ''').df()\n",
        "\n",
        "    df_samples.to_csv(SAMPLE_CSV, index=False)\n",
        "    print(\"‚úÖ sample √©crit :\", SAMPLE_CSV)\n",
        "    print(df_samples.groupby(\"stake_label\")[\"player_id\"].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "289bf428",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "289bf428",
        "outputId": "4d882486-b1c2-427d-cc82-2ff6d00791b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fonctions transcript pr√™tes\n",
            "‚úÖ Patch appliqu√© : le player_id sera affich√© dans la 1√®re ligne de chaque main export√©e.\n"
          ]
        }
      ],
      "source": [
        "import json, re\n",
        "\n",
        "def split_actions_to_streets(actions):\n",
        "    streets = {\"preflop\": [], \"flop\": [], \"turn\": [], \"river\": [], \"showdown\": []}\n",
        "    board   = {\"flop\": None, \"turn\": None, \"river\": None}\n",
        "    current = \"preflop\"\n",
        "    for a in actions:\n",
        "        if a.startswith(\"d dh\"):\n",
        "            continue\n",
        "        if a.startswith(\"d db \"):\n",
        "            cards = a.split(\" \", 2)[2]\n",
        "            if board[\"flop\"] is None:\n",
        "                board[\"flop\"] = cards; current=\"flop\";  continue\n",
        "            if board[\"turn\"] is None:\n",
        "                board[\"turn\"] = cards; current=\"turn\";  continue\n",
        "            if board[\"river\"] is None:\n",
        "                board[\"river\"] = cards; current=\"river\"; continue\n",
        "        if a.startswith(\"p\") and \" sm\" in a:\n",
        "            streets[\"showdown\"].append(a); continue\n",
        "        streets[current].append(a)\n",
        "    return streets, board\n",
        "\n",
        "def parse_action(act: str, street: str):\n",
        "    m = re.match(r\"p(\\d+)\\s+(.*)\", act)\n",
        "    if not m:\n",
        "        return None, act\n",
        "    pid = int(m.group(1))\n",
        "    rest = m.group(2).strip()\n",
        "\n",
        "    if rest == \"f\":\n",
        "        txt = \"fold\"\n",
        "    elif rest == \"cc\":\n",
        "        txt = \"call/check\"\n",
        "    else:\n",
        "        m2 = re.match(r\"cbr\\s+([0-9.]+)\", rest)\n",
        "        if m2:\n",
        "            amt = m2.group(1)\n",
        "            txt = f\"bet/raise {amt}\"\n",
        "        else:\n",
        "            txt = rest\n",
        "    return pid, txt\n",
        "\n",
        "def make_hand_transcript(row):\n",
        "    actions = json.loads(row[\"actions_json\"])\n",
        "    players = json.loads(row[\"players_json\"])\n",
        "    stacks  = json.loads(row[\"starting_stacks_json\"])\n",
        "\n",
        "    streets, board = split_actions_to_streets(actions)\n",
        "\n",
        "    # rep√®re le seat_idx de notre joueur (pX)\n",
        "    hero_p = int(row[\"seat_idx\"])\n",
        "\n",
        "    header = (\n",
        "        f\"{row['ts']} | hand_uid={row['hand_uid']} | table={row['table_id'][:10]}... | \"\n",
        "        f\"hero=p{hero_p} ({row['pos_label']}) | start={row['starting_stack']} | \"\n",
        "        f\"net_from_stacks={row['net_from_stacks']}\"\n",
        "    )\n",
        "\n",
        "    def fmt_street(st):\n",
        "        out = []\n",
        "        for a in streets[st]:\n",
        "            pid, txt = parse_action(a, st)\n",
        "            if pid is None:\n",
        "                continue\n",
        "            tag = \"HERO\" if pid == hero_p else \"VIL \"\n",
        "            out.append(f\"{tag} p{pid}: {txt}\")\n",
        "        return out\n",
        "\n",
        "    lines = [header]\n",
        "    lines.append(\"  Preflop:\")\n",
        "    lines += [\"   - \" + x for x in fmt_street(\"preflop\")] or [\"   - (‚Äî)\"]\n",
        "\n",
        "    if board[\"flop\"]:\n",
        "        lines.append(f\"  Flop {board['flop']}:\")\n",
        "        lines += [\"   - \" + x for x in fmt_street(\"flop\")] or [\"   - (‚Äî)\"]\n",
        "    if board[\"turn\"]:\n",
        "        lines.append(f\"  Turn {board['turn']}:\")\n",
        "        lines += [\"   - \" + x for x in fmt_street(\"turn\")] or [\"   - (‚Äî)\"]\n",
        "    if board[\"river\"]:\n",
        "        lines.append(f\"  River {board['river']}:\")\n",
        "        lines += [\"   - \" + x for x in fmt_street(\"river\")] or [\"   - (‚Äî)\"]\n",
        "\n",
        "    if streets[\"showdown\"]:\n",
        "        lines.append(\"  Showdown:\")\n",
        "        for a in streets[\"showdown\"]:\n",
        "            pid, rest = parse_action(a, \"showdown\")\n",
        "            if pid is None:\n",
        "                continue\n",
        "            tag = \"HERO\" if pid == hero_p else \"VIL \"\n",
        "            lines.append(f\"   - {tag} p{pid}: shows {a.split('sm',1)[1].strip()}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\"‚úÖ Fonctions transcript pr√™tes\")\n",
        "\n",
        "\n",
        "# === PATCH : injecter player_id dans le header du transcript ===\n",
        "# (sans toucher au reste : on wrappe l'ancienne fonction)\n",
        "\n",
        "make_hand_transcript_old = make_hand_transcript  # on garde l'ancienne\n",
        "\n",
        "def make_hand_transcript(row):\n",
        "    txt = make_hand_transcript_old(row)\n",
        "\n",
        "    pid = row.get(\"player_id\", None) if hasattr(row, \"get\") else None\n",
        "    if pid is None:\n",
        "        return txt\n",
        "\n",
        "    pid_short = str(pid)[:16]  # tronqu√© (tu peux mettre [:32] si tu veux)\n",
        "\n",
        "    lines = txt.splitlines()\n",
        "    if not lines:\n",
        "        return txt\n",
        "\n",
        "    # √©vite doublon si d√©j√† pr√©sent\n",
        "    if \"player_id=\" in lines[0]:\n",
        "        return txt\n",
        "\n",
        "    # injection propre\n",
        "    if \" | hero=\" in lines[0]:\n",
        "        lines[0] = lines[0].replace(\" | hero=\", f\" | player_id={pid_short} | hero=\", 1)\n",
        "    else:\n",
        "        lines[0] = lines[0] + f\" | player_id={pid_short}\"\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\"‚úÖ Patch appliqu√© : le player_id sera affich√© dans la 1√®re ligne de chaque main export√©e.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "37a9dd78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37a9dd78",
        "outputId": "29ccdc9d-8254-46ab-dfac-24efde2d84ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fonctions build_player_df / export_player_transcript pr√™tes\n",
            "üìÅ Export dir: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts\n"
          ]
        }
      ],
      "source": [
        "import os, duckdb, pandas as pd, hashlib\n",
        "\n",
        "OUT_ROOT_FULL  = \"/content/drive/MyDrive/pokerstars_clean/follow_20pct_full\"\n",
        "TIMELINE_DIR_FULL = f\"{OUT_ROOT_FULL}/timeline_parquet\"\n",
        "HANDS_DIR_FULL    = f\"{OUT_ROOT_FULL}/hands_parquet\"\n",
        "\n",
        "EXPORT_DIR = f\"{OUT_ROOT_FULL}/player_transcripts\"\n",
        "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "\n",
        "def bucket(pid: str, n=256):\n",
        "    return int(hashlib.md5(pid.encode(\"utf-8\")).hexdigest()[:8], 16) % n\n",
        "\n",
        "def build_player_df(player_id: str, stake_label: int, limit_hands: int = 200):\n",
        "    \"\"\"\n",
        "    Renvoie un DF (timeline + actions) pour un joueur donn√© sur un stake.\n",
        "    \"\"\"\n",
        "    b = bucket(player_id)\n",
        "    con = duckdb.connect()\n",
        "    con.execute(\"PRAGMA threads=4;\")\n",
        "\n",
        "    tl = con.execute(f\"\"\"\n",
        "    SELECT *\n",
        "    FROM parquet_scan('{TIMELINE_DIR_FULL}/stake_label={stake_label}/player_bucket={b:03d}/*.parquet')\n",
        "    WHERE player_id = '{player_id}'\n",
        "    ORDER BY table_id, ts, hand_uid\n",
        "    LIMIT {int(limit_hands)}\n",
        "    \"\"\").df()\n",
        "\n",
        "    if len(tl) == 0:\n",
        "        return tl\n",
        "\n",
        "    hands = con.execute(f\"\"\"\n",
        "    SELECT ts, hand_uid, table_id, actions_json, players_json, starting_stacks_json\n",
        "    FROM parquet_scan('{HANDS_DIR_FULL}/stake_label={stake_label}/*.parquet')\n",
        "    WHERE (table_id, hand_uid) IN (SELECT table_id, hand_uid FROM tl)\n",
        "    \"\"\").df()\n",
        "\n",
        "    df = tl.merge(hands, on=[\"ts\",\"hand_uid\",\"table_id\"], how=\"left\") \\\n",
        "           .sort_values([\"table_id\",\"ts\",\"hand_uid\"]) \\\n",
        "           .reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def export_player_transcript(player_id: str, stake_label: int, n_hands: int = 50, filename=None):\n",
        "    dfp = build_player_df(player_id, stake_label, limit_hands=n_hands)\n",
        "    dfp = dfp[dfp[\"actions_json\"].notna()].copy()\n",
        "\n",
        "    if filename is None:\n",
        "        filename = f\"stake{stake_label}_player_{player_id[:12]}_first{n_hands}.txt\"\n",
        "    out_path = os.path.join(EXPORT_DIR, filename)\n",
        "\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for k in range(min(n_hands, len(dfp))):\n",
        "            f.write(\"=\"*120 + \"\\n\")\n",
        "            f.write(make_hand_transcript(dfp.iloc[k]) + \"\\n\\n\")\n",
        "\n",
        "    print(\"‚úÖ Export √©crit:\", out_path)\n",
        "    print(\"   mains √©crites:\", min(n_hands, len(dfp)))\n",
        "    return out_path\n",
        "\n",
        "print(\"‚úÖ Fonctions build_player_df / export_player_transcript pr√™tes\")\n",
        "print(\"üìÅ Export dir:\", EXPORT_DIR)\n",
        "\n",
        "\n",
        "\n",
        "# --- Override: export_player_transcript SAFE (atomic write + mkdir) ---\n",
        "import inspect\n",
        "\n",
        "def export_player_transcript(player_id: str, stake_label: int, n_hands: int = 200, filename=None, player_bucket=None):\n",
        "    # build_player_df peut (ou non) accepter player_bucket selon ta version\n",
        "    sig = inspect.signature(build_player_df)\n",
        "    kwargs = {\"player_id\": player_id, \"stake_label\": int(stake_label), \"limit_hands\": int(n_hands)}\n",
        "    if \"player_bucket\" in sig.parameters and player_bucket is not None:\n",
        "        kwargs[\"player_bucket\"] = int(player_bucket)\n",
        "\n",
        "    dfp = build_player_df(**kwargs)\n",
        "\n",
        "    # Filtre actions_json si la colonne existe\n",
        "    if \"actions_json\" in dfp.columns:\n",
        "        dfp2 = dfp[dfp[\"actions_json\"].notna()].copy()\n",
        "    else:\n",
        "        dfp2 = dfp.copy()\n",
        "\n",
        "    if len(dfp2) == 0:\n",
        "        raise ValueError(\"Aucune main exploitable (df vide apr√®s filtrage actions_json).\")\n",
        "\n",
        "    # Chemin de sortie\n",
        "    if filename is None:\n",
        "        base_dir = globals().get(\"EXPORT_DIR\", \".\")\n",
        "        filename = f\"stake{stake_label}_player_{str(player_id)[:12]}_first{min(int(n_hands), len(dfp2))}.txt\"\n",
        "        out_path = os.path.join(base_dir, filename)\n",
        "    else:\n",
        "        out_path = filename if str(filename).startswith(\"/\") else os.path.join(globals().get(\"EXPORT_DIR\", \".\"), filename)\n",
        "\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "\n",
        "    # √âcriture safe : tmp puis rename (jamais de fichier final vide)\n",
        "    tmp_path = out_path + \".tmp\"\n",
        "    n = min(int(n_hands), len(dfp2))\n",
        "\n",
        "    with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for k in range(n):\n",
        "            f.write(\"=\" * 120 + \"\\n\")\n",
        "            f.write(make_hand_transcript(dfp2.iloc[k]) + \"\\n\\n\")\n",
        "\n",
        "    os.replace(tmp_path, out_path)\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "249ded64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249ded64",
        "outputId": "cc898723-31b2-4f3c-e818-110c2d93fff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≠Ô∏è  STEP 4 skipped: des transcripts TXT existent d√©j√† + manifest pr√©sent.\n",
            "TXT count: 1468\n",
            "Manifest: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/exports_manifest.csv\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# STEP 4 ‚Äî Export BULK transcripts TXT (300 joueurs / stake, 200 mains / joueur)\n",
        "# =========================\n",
        "\n",
        "FORCE_REEXPORT_TRANSCRIPTS = False\n",
        "N_HANDS_PER_PLAYER = 200\n",
        "\n",
        "if not os.path.exists(SAMPLE_CSV):\n",
        "    raise FileNotFoundError(f\"‚ùå sample_players_balanced.csv introuvable : {SAMPLE_CSV}\")\n",
        "\n",
        "existing_txt = glob.glob(os.path.join(EXPORT_BULK_DIR, \"stake_label=*\", \"*.txt\"))\n",
        "manifest_path = os.path.join(EXPORT_BULK_DIR, \"exports_manifest.csv\")\n",
        "\n",
        "if existing_txt and os.path.exists(manifest_path) and not FORCE_REEXPORT_TRANSCRIPTS:\n",
        "    print(\"‚è≠Ô∏è  STEP 4 skipped: des transcripts TXT existent d√©j√† + manifest pr√©sent.\")\n",
        "    print(\"TXT count:\", len(existing_txt))\n",
        "    print(\"Manifest:\", manifest_path)\n",
        "else:\n",
        "    os.makedirs(EXPORT_BULK_DIR, exist_ok=True)\n",
        "\n",
        "    df_samples = pd.read_csv(SAMPLE_CSV)\n",
        "\n",
        "    need_cols = {\"stake_label\", \"player_id\"}\n",
        "    missing = need_cols - set(df_samples.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"‚ùå Colonnes manquantes dans sample_players_balanced.csv: {missing}\")\n",
        "\n",
        "    manifest = []\n",
        "    errors = []\n",
        "\n",
        "    for stake, sub in df_samples.groupby(\"stake_label\"):\n",
        "        out_dir_stake = os.path.join(EXPORT_BULK_DIR, f\"stake_label={int(stake)}\")\n",
        "        os.makedirs(out_dir_stake, exist_ok=True)\n",
        "\n",
        "        players = sub[\"player_id\"].astype(str).tolist()\n",
        "        print(f\"\\nStake {int(stake)} | joueurs: {len(players)} | out={out_dir_stake}\")\n",
        "\n",
        "        for i, pid in enumerate(players, start=1):\n",
        "            fname = f\"stake{int(stake)}_player_{pid[:12]}_first{N_HANDS_PER_PLAYER}.txt\"\n",
        "            out_path = os.path.join(out_dir_stake, fname)\n",
        "\n",
        "            # Pour pouvoir relancer sans tout refaire\n",
        "            if os.path.exists(out_path) and os.path.getsize(out_path) > 0 and not FORCE_REEXPORT_TRANSCRIPTS:\n",
        "                manifest.append({\"stake_label\": int(stake), \"player_id\": pid, \"txt_path\": out_path, \"status\": \"skipped_exists\"})\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                export_player_transcript(\n",
        "                    player_id=pid,\n",
        "                    stake_label=int(stake),\n",
        "                    n_hands=int(N_HANDS_PER_PLAYER),\n",
        "                    filename=out_path,\n",
        "                )\n",
        "                manifest.append({\"stake_label\": int(stake), \"player_id\": pid, \"txt_path\": out_path, \"status\": \"ok\"})\n",
        "            except Exception as e:\n",
        "                errors.append({\"stake_label\": int(stake), \"player_id\": pid, \"error\": repr(e)})\n",
        "                manifest.append({\"stake_label\": int(stake), \"player_id\": pid, \"txt_path\": out_path, \"status\": \"error\"})\n",
        "\n",
        "            if i % 25 == 0:\n",
        "                print(f\"  ... {i}/{len(players)} joueurs trait√©s\")\n",
        "\n",
        "    # Sauvegarder manifest + erreurs (overwrite)\n",
        "    pd.DataFrame(manifest).to_csv(manifest_path, index=False)\n",
        "\n",
        "    errors_path = os.path.join(EXPORT_BULK_DIR, \"exports_errors.csv\")\n",
        "    pd.DataFrame(errors).to_csv(errors_path, index=False)\n",
        "\n",
        "    print(\"\\n‚úÖ STEP 4 termin√©.\")\n",
        "    print(\"Manifest :\", manifest_path)\n",
        "    print(\"Erreurs  :\", errors_path)\n",
        "    print(\"Nb OK/skip:\", sum(r.get(\"status\") in [\"ok\", \"skipped_exists\"] for r in manifest))\n",
        "    print(\"Nb erreurs:\", len(errors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7f85c6d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f85c6d8",
        "outputId": "b68c1263-e495-4f73-de82-548f81aa2239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≠Ô∏è  STEP 5 skipped: dataset structur√© d√©j√† pr√©sent.\n",
            " - /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/_structured/hands_parquet\n",
            " - /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/_structured/actions_parquet\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# STEP 5 ‚Äî Structuration des transcripts TXT -> Parquet (_structured/hands_parquet + actions_parquet)\n",
        "# =========================\n",
        "\n",
        "FORCE_RESTRUCTURE_TRANSCRIPTS = False  # <- True pour supprimer _structured et tout reconstruire\n",
        "\n",
        "EXPORT_BULK_DIR_PATH = EXPORT_BULK_DIR\n",
        "\n",
        "# Si le dataset structur√© existe d√©j√†, on skip (par d√©faut)\n",
        "if dir_has_files(STRUCT_HANDS_DIR) and dir_has_files(STRUCT_ACT_DIR) and not FORCE_RESTRUCTURE_TRANSCRIPTS:\n",
        "    print(\"‚è≠Ô∏è  STEP 5 skipped: dataset structur√© d√©j√† pr√©sent.\")\n",
        "    print(\" -\", STRUCT_HANDS_DIR)\n",
        "    print(\" -\", STRUCT_ACT_DIR)\n",
        "else:\n",
        "    # =========================\n",
        "    # PokerStars TRANSCRIPTS TXT -> Parquet\n",
        "    # (hands + actions) with stake_label + player_id\n",
        "    # =========================\n",
        "\n",
        "    import os, re, glob, json, time, shutil\n",
        "    import pandas as pd\n",
        "\n",
        "    try:\n",
        "        from tqdm import tqdm\n",
        "    except Exception:\n",
        "        def tqdm(x, **kwargs):  # fallback\n",
        "            return x\n",
        "\n",
        "    # ---------\n",
        "    # CONFIG\n",
        "    # ---------\n",
        "    EXPORT_BULK_DIR = EXPORT_BULK_DIR_PATH\n",
        "\n",
        "    STRUCT_DIR = os.path.join(EXPORT_BULK_DIR, \"_structured\")\n",
        "    HANDS_DIR  = os.path.join(STRUCT_DIR, \"hands_parquet\")\n",
        "    ACT_DIR    = os.path.join(STRUCT_DIR, \"actions_parquet\")\n",
        "\n",
        "    MANIFEST_PATH = os.path.join(STRUCT_DIR, \"_manifest_processed.txt\")\n",
        "    ERRORS_PATH   = os.path.join(STRUCT_DIR, \"_errors.log\")\n",
        "\n",
        "    # si tu veux forcer un rerun complet (efface manifest + dossiers parquet) -> mets True\n",
        "    FORCE_RERUN = FORCE_RESTRUCTURE_TRANSCRIPTS\n",
        "\n",
        "    CHUNK_HANDS   = 10_000\n",
        "    CHUNK_ACTIONS = 200_000\n",
        "\n",
        "    # ---------\n",
        "    # SETUP\n",
        "    # ---------\n",
        "    os.makedirs(STRUCT_DIR, exist_ok=True)\n",
        "    os.makedirs(HANDS_DIR, exist_ok=True)\n",
        "    os.makedirs(ACT_DIR, exist_ok=True)\n",
        "\n",
        "    if FORCE_RERUN:\n",
        "        for p in [MANIFEST_PATH, ERRORS_PATH]:\n",
        "            if os.path.exists(p):\n",
        "                os.remove(p)\n",
        "        for d in [HANDS_DIR, ACT_DIR]:\n",
        "            if os.path.exists(d):\n",
        "                shutil.rmtree(d)\n",
        "            os.makedirs(d, exist_ok=True)\n",
        "        print(\"FORCE_RERUN: reset manifest + parquet dirs ‚úÖ\")\n",
        "\n",
        "    # ---------\n",
        "    # HELPERS\n",
        "    # ---------\n",
        "    # Chaque main commence par une ligne type:\n",
        "    # 2009-07-14 18:28:13 | hand_uid=... | table=... | hero=p4 (BTN) | start=... | net_from_stacks=...\n",
        "    HAND_START_RE = re.compile(r\"(?m)^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\s*\\|\\s*hand_uid=\")\n",
        "\n",
        "    def _log_error(msg: str):\n",
        "        with open(ERRORS_PATH, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(msg.rstrip() + \"\\n\")\n",
        "\n",
        "    def parse_stake_label(path: str) -> int:\n",
        "        m = re.search(r\"stake_label=(\\d+)\", path)\n",
        "        return int(m.group(1)) if m else -1\n",
        "\n",
        "    def parse_player_id_from_filename(path: str) -> str:\n",
        "        base = os.path.basename(path)\n",
        "        m = re.search(r\"player_(.+?)_first\\d+\\.txt$\", base)\n",
        "        if m:\n",
        "            return m.group(1)\n",
        "        m2 = re.search(r\"player_(.+?)\\.txt$\", base)\n",
        "        return m2.group(1) if m2 else base.replace(\".txt\", \"\")\n",
        "\n",
        "    def split_hand_blocks(text: str):\n",
        "        starts = [m.start() for m in HAND_START_RE.finditer(text)]\n",
        "        if not starts:\n",
        "            return []\n",
        "        blocks = []\n",
        "        for i, s in enumerate(starts):\n",
        "            e = starts[i+1] if i+1 < len(starts) else len(text)\n",
        "            blk = text[s:e].strip()\n",
        "            if blk:\n",
        "                blocks.append(blk)\n",
        "        return blocks\n",
        "\n",
        "    def parse_action_line(rest: str):\n",
        "        \"\"\"\n",
        "        Transcript actions examples:\n",
        "          \"fold\"\n",
        "          \"call/check\"\n",
        "          \"bet/raise 30\"\n",
        "          \"bet/raise 98.50\"\n",
        "        \"\"\"\n",
        "        r = (rest or \"\").strip()\n",
        "        low = r.lower()\n",
        "\n",
        "        nums = re.findall(r\"-?\\d+(?:\\.\\d+)?\", r)\n",
        "        amt = float(nums[-1]) if nums else None\n",
        "\n",
        "        if \"fold\" in low:\n",
        "            return {\"action_type\": \"fold\", \"amount\": 0.0, \"is_all_in\": False}\n",
        "\n",
        "        if low in {\"call/check\", \"check/call\"} or \"call/check\" in low or \"check/call\" in low:\n",
        "            return {\"action_type\": \"call_or_check\", \"amount\": None, \"is_all_in\": False}\n",
        "\n",
        "        if low.startswith(\"bet/raise\"):\n",
        "            return {\"action_type\": \"bet_or_raise\", \"amount\": amt, \"is_all_in\": False}\n",
        "\n",
        "        if low.startswith(\"bet \"):\n",
        "            return {\"action_type\": \"bet\", \"amount\": amt, \"is_all_in\": False}\n",
        "\n",
        "        if low.startswith(\"raise \"):\n",
        "            return {\"action_type\": \"raise\", \"amount\": amt, \"is_all_in\": False}\n",
        "\n",
        "        if \"check\" in low and \"call\" not in low:\n",
        "            return {\"action_type\": \"check\", \"amount\": 0.0, \"is_all_in\": False}\n",
        "\n",
        "        if \"call\" in low and \"check\" not in low:\n",
        "            return {\"action_type\": \"call\", \"amount\": amt, \"is_all_in\": False}\n",
        "\n",
        "        return {\"action_type\": \"other\", \"amount\": amt, \"is_all_in\": False}\n",
        "\n",
        "    def parse_hand_block(block: str, stake_label: int, player_id: str, source_file: str, hand_index_in_file: int):\n",
        "        \"\"\"\n",
        "        Header example:\n",
        "        2009-07-14 18:28:13 | hand_uid=60931459206 | table=... | hero=p4 (BTN) | start=261.0 | net_from_stacks=18.5\n",
        "\n",
        "        Streets:\n",
        "          Preflop:\n",
        "          Flop Jc9c4c:\n",
        "          Turn 3d:\n",
        "          River 6c:\n",
        "\n",
        "        Actions:\n",
        "          - VIL p3: fold\n",
        "          - HERO p4: call/check\n",
        "          - VIL p5: bet/raise 98.50\n",
        "        \"\"\"\n",
        "        lines = [ln.rstrip(\"\\n\") for ln in block.splitlines() if ln.strip() != \"\"]\n",
        "        if not lines:\n",
        "            return None, []\n",
        "\n",
        "        header = lines[0].strip()\n",
        "\n",
        "        # parsing header robuste\n",
        "        hm = re.match(\n",
        "            r\"^(?P<dt>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s*\\|\\s*\"\n",
        "            r\"hand_uid=(?P<hand_uid>\\d+)\\s*\\|\\s*\"\n",
        "            r\"table=(?P<table>[^|]+?)\\s*\\|\\s*\"\n",
        "            r\"hero=(?P<hero_player>p\\d+)\\s*\\((?P<hero_pos>[^)]+)\\)\\s*\\|\\s*\"\n",
        "            r\"start=(?P<start>-?\\d+(?:\\.\\d+)?)\\s*\\|\\s*\"\n",
        "            r\"net_from_stacks=(?P<net>-?\\d+(?:\\.\\d+)?)\\s*$\",\n",
        "            header\n",
        "        )\n",
        "\n",
        "        ts = hm.group(\"dt\") if hm else None\n",
        "        hand_uid = int(hm.group(\"hand_uid\")) if hm else None\n",
        "        table_id = hm.group(\"table\").strip() if hm else None\n",
        "        hero_player = hm.group(\"hero_player\").strip() if hm else None\n",
        "        hero_pos = hm.group(\"hero_pos\").strip() if hm else None\n",
        "        start_val = float(hm.group(\"start\")) if hm else None\n",
        "        net_from_stacks = float(hm.group(\"net\")) if hm else None\n",
        "\n",
        "        board_flop = None\n",
        "        board_turn = None\n",
        "        board_river = None\n",
        "\n",
        "        current_street = None\n",
        "        action_rows = []\n",
        "        action_no = 0\n",
        "\n",
        "        for ln in lines[1:]:\n",
        "            s = ln.strip()\n",
        "\n",
        "            # street headers\n",
        "            if s.lower().startswith(\"preflop\"):\n",
        "                current_street = \"PREFLOP\"\n",
        "                continue\n",
        "\n",
        "            if s.lower().startswith(\"flop\"):\n",
        "                current_street = \"FLOP\"\n",
        "                cards = re.findall(r\"[2-9TJQKA][cdhs]\", s)\n",
        "                if cards:\n",
        "                    board_flop = \" \".join(cards[:3])\n",
        "                continue\n",
        "\n",
        "            if s.lower().startswith(\"turn\"):\n",
        "                current_street = \"TURN\"\n",
        "                cards = re.findall(r\"[2-9TJQKA][cdhs]\", s)\n",
        "                if cards:\n",
        "                    board_turn = cards[-1]\n",
        "                continue\n",
        "\n",
        "            if s.lower().startswith(\"river\"):\n",
        "                current_street = \"RIVER\"\n",
        "                cards = re.findall(r\"[2-9TJQKA][cdhs]\", s)\n",
        "                if cards:\n",
        "                    board_river = cards[-1]\n",
        "                continue\n",
        "\n",
        "            # action lines: \"- VIL p2: fold\" / \"- HERO p4: bet/raise 30\"\n",
        "            am = re.match(r\"^-+\\s*(?P<role>HERO|VIL)\\s+(?P<p>p\\d+)\\s*:\\s*(?P<rest>.+)$\", s, flags=re.IGNORECASE)\n",
        "            if not am:\n",
        "                continue\n",
        "\n",
        "            role = am.group(\"role\").upper()\n",
        "            actor_p = am.group(\"p\")\n",
        "            rest = am.group(\"rest\").strip()\n",
        "\n",
        "            parsed = parse_action_line(rest)\n",
        "\n",
        "            action_no += 1\n",
        "            action_rows.append({\n",
        "                \"stake_label\": stake_label,\n",
        "                \"player_id\": player_id,\n",
        "                \"source_file\": source_file,\n",
        "                \"ts\": ts,\n",
        "                \"hand_uid\": hand_uid,\n",
        "                \"hand_id\": hand_uid,   # alias pratique\n",
        "                \"table_id\": table_id,\n",
        "                \"street\": current_street,\n",
        "                \"action_no\": action_no,\n",
        "                \"actor_role\": role,     # HERO / VIL\n",
        "                \"actor_player\": actor_p,# p4, p3, ...\n",
        "                \"is_hero\": (role == \"HERO\"),\n",
        "                \"action_type\": parsed[\"action_type\"],\n",
        "                \"amount\": parsed[\"amount\"],\n",
        "                \"raw_action\": rest,\n",
        "            })\n",
        "\n",
        "        hand_row = {\n",
        "            \"stake_label\": stake_label,\n",
        "            \"player_id\": player_id,\n",
        "            \"source_file\": source_file,\n",
        "            \"hand_index_in_file\": hand_index_in_file,\n",
        "            \"ts\": ts,\n",
        "            \"hand_uid\": hand_uid,\n",
        "            \"hand_id\": hand_uid,   # alias pratique\n",
        "            \"table_id\": table_id,\n",
        "            \"hero_player\": hero_player,\n",
        "            \"hero_pos\": hero_pos,\n",
        "            \"start\": start_val,\n",
        "            \"net_from_stacks\": net_from_stacks,\n",
        "            \"board_flop\": board_flop,\n",
        "            \"board_turn\": board_turn,\n",
        "            \"board_river\": board_river,\n",
        "        }\n",
        "\n",
        "        return hand_row, action_rows\n",
        "\n",
        "    def write_part(df: pd.DataFrame, out_dir: str, stake_label: int, part_idx: int, kind: str):\n",
        "        stake_dir = os.path.join(out_dir, f\"stake_label={stake_label}\")\n",
        "        os.makedirs(stake_dir, exist_ok=True)\n",
        "        out_path = os.path.join(stake_dir, f\"{kind}_part-{part_idx:05d}.parquet\")\n",
        "        df.to_parquet(out_path, index=False, engine=\"pyarrow\")\n",
        "        return out_path\n",
        "\n",
        "    # ---------\n",
        "    # RESUME MANIFEST\n",
        "    # ---------\n",
        "    processed = set()\n",
        "    if os.path.exists(MANIFEST_PATH):\n",
        "        with open(MANIFEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            for ln in f:\n",
        "                p = ln.strip()\n",
        "                if p:\n",
        "                    processed.add(p)\n",
        "\n",
        "    # ---------\n",
        "    # MAIN\n",
        "    # ---------\n",
        "    txt_files = glob.glob(os.path.join(EXPORT_BULK_DIR, \"stake_label=*\", \"*.txt\"))\n",
        "    txt_files = sorted(txt_files, key=lambda p: (parse_stake_label(p), p))\n",
        "\n",
        "    print(\"EXPORT_BULK_DIR:\", EXPORT_BULK_DIR, \"| exists:\", os.path.exists(EXPORT_BULK_DIR))\n",
        "    print(\"TXT files found:\", len(txt_files))\n",
        "    print(\"Already processed:\", len(processed))\n",
        "    print(\"Output STRUCT_DIR:\", STRUCT_DIR)\n",
        "\n",
        "    hands_buffer = []\n",
        "    actions_buffer = []\n",
        "\n",
        "    current_stake = None\n",
        "    hands_part_idx = 0\n",
        "    actions_part_idx = 0\n",
        "\n",
        "    total_hands = 0\n",
        "    total_actions = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    for path in tqdm(txt_files, desc=\"Parsing TXT\"):\n",
        "        if path in processed:\n",
        "            continue\n",
        "\n",
        "        stake_label = parse_stake_label(path)\n",
        "        player_id = parse_player_id_from_filename(path)\n",
        "\n",
        "        # switch stake -> flush previous stake buffers + reset part index\n",
        "        if current_stake is None:\n",
        "            current_stake = stake_label\n",
        "\n",
        "        if stake_label != current_stake:\n",
        "            if hands_buffer:\n",
        "                dfh = pd.DataFrame(hands_buffer)\n",
        "                write_part(dfh, HANDS_DIR, current_stake, hands_part_idx, kind=\"hands\")\n",
        "                hands_part_idx += 1\n",
        "                hands_buffer = []\n",
        "            if actions_buffer:\n",
        "                dfa = pd.DataFrame(actions_buffer)\n",
        "                write_part(dfa, ACT_DIR, current_stake, actions_part_idx, kind=\"actions\")\n",
        "                actions_part_idx += 1\n",
        "                actions_buffer = []\n",
        "\n",
        "            current_stake = stake_label\n",
        "            hands_part_idx = 0\n",
        "            actions_part_idx = 0\n",
        "\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "                text = f.read()\n",
        "        except Exception as e:\n",
        "            _log_error(f\"[READ_FAIL] {path} | {repr(e)}\")\n",
        "            continue\n",
        "\n",
        "        blocks = split_hand_blocks(text)\n",
        "        if not blocks:\n",
        "            _log_error(f\"[NO_HANDS_FOUND] {path}\")\n",
        "            with open(MANIFEST_PATH, \"a\", encoding=\"utf-8\") as f:\n",
        "                f.write(path + \"\\n\")\n",
        "            processed.add(path)\n",
        "            continue\n",
        "\n",
        "        for hi, blk in enumerate(blocks):\n",
        "            try:\n",
        "                hand_row, action_rows = parse_hand_block(\n",
        "                    blk,\n",
        "                    stake_label=stake_label,\n",
        "                    player_id=player_id,\n",
        "                    source_file=path,\n",
        "                    hand_index_in_file=hi\n",
        "                )\n",
        "\n",
        "                if hand_row is not None:\n",
        "                    hands_buffer.append(hand_row)\n",
        "                    total_hands += 1\n",
        "\n",
        "                if action_rows:\n",
        "                    actions_buffer.extend(action_rows)\n",
        "                    total_actions += len(action_rows)\n",
        "\n",
        "            except Exception as e:\n",
        "                _log_error(f\"[PARSE_FAIL] {path} | hand_idx={hi} | {repr(e)}\")\n",
        "                continue\n",
        "\n",
        "            # chunk flush\n",
        "            if len(hands_buffer) >= CHUNK_HANDS:\n",
        "                dfh = pd.DataFrame(hands_buffer)\n",
        "                write_part(dfh, HANDS_DIR, current_stake, hands_part_idx, kind=\"hands\")\n",
        "                hands_part_idx += 1\n",
        "                hands_buffer = []\n",
        "\n",
        "            if len(actions_buffer) >= CHUNK_ACTIONS:\n",
        "                dfa = pd.DataFrame(actions_buffer)\n",
        "                write_part(dfa, ACT_DIR, current_stake, actions_part_idx, kind=\"actions\")\n",
        "                actions_part_idx += 1\n",
        "                actions_buffer = []\n",
        "\n",
        "        # mark processed file\n",
        "        with open(MANIFEST_PATH, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(path + \"\\n\")\n",
        "        processed.add(path)\n",
        "\n",
        "    # final flush\n",
        "    if current_stake is not None:\n",
        "        if hands_buffer:\n",
        "            dfh = pd.DataFrame(hands_buffer)\n",
        "            write_part(dfh, HANDS_DIR, current_stake, hands_part_idx, kind=\"hands\")\n",
        "            hands_part_idx += 1\n",
        "            hands_buffer = []\n",
        "        if actions_buffer:\n",
        "            dfa = pd.DataFrame(actions_buffer)\n",
        "            write_part(dfa, ACT_DIR, current_stake, actions_part_idx, kind=\"actions\")\n",
        "            actions_part_idx += 1\n",
        "            actions_buffer = []\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(\"\\n‚úÖ DONE\")\n",
        "    print(\"Hands parsed:\", total_hands)\n",
        "    print(\"Actions parsed:\", total_actions)\n",
        "    print(f\"Elapsed: {dt:.1f}s\")\n",
        "    print(\"Hands output dir:\", HANDS_DIR)\n",
        "    print(\"Actions output dir:\", ACT_DIR)\n",
        "    print(\"Manifest:\", MANIFEST_PATH)\n",
        "    print(\"Errors (if any):\", ERRORS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "78438509",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78438509",
        "outputId": "689f40cc-d876-4cbf-9193-0c102380e36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- OUTPUT SUMMARY ---\n",
            "hands_parquet: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/hands_parquet | parquet: 279\n",
            "player_hands_parquet: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_hands_parquet | parquet: 1528\n",
            "timeline_parquet: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/timeline_parquet | parquet: 19290\n",
            "sample_csv: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/sample_players_balanced.csv | exists: True\n",
            "bulk_txt: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h | txt: 1469\n",
            "structured hands: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/_structured/hands_parquet | parquet: 13\n",
            "structured actions: /content/drive/MyDrive/pokerstars_clean/follow_20pct_full/player_transcripts_bulk_300p_200h/_structured/actions_parquet | parquet: 7\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# FINAL ‚Äî Sanity checks (light)\n",
        "# =========================\n",
        "\n",
        "def count_parquet(root: str) -> int:\n",
        "    if not os.path.exists(root):\n",
        "        return 0\n",
        "    return len(glob.glob(os.path.join(root, \"**\", \"*.parquet\"), recursive=True))\n",
        "\n",
        "def count_txt(root: str) -> int:\n",
        "    if not os.path.exists(root):\n",
        "        return 0\n",
        "    return len(glob.glob(os.path.join(root, \"**\", \"*.txt\"), recursive=True))\n",
        "\n",
        "print(\"\\n--- OUTPUT SUMMARY ---\")\n",
        "print(\"hands_parquet:\", HANDS_DIR_FULL, \"| parquet:\", count_parquet(HANDS_DIR_FULL))\n",
        "print(\"player_hands_parquet:\", PH_DIR_FULL, \"| parquet:\", count_parquet(PH_DIR_FULL))\n",
        "print(\"timeline_parquet:\", TIMELINE_DIR_FULL, \"| parquet:\", count_parquet(TIMELINE_DIR_FULL))\n",
        "print(\"sample_csv:\", SAMPLE_CSV, \"| exists:\", os.path.exists(SAMPLE_CSV))\n",
        "print(\"bulk_txt:\", EXPORT_BULK_DIR, \"| txt:\", count_txt(EXPORT_BULK_DIR))\n",
        "print(\"structured hands:\", STRUCT_HANDS_DIR, \"| parquet:\", count_parquet(STRUCT_HANDS_DIR))\n",
        "print(\"structured actions:\", STRUCT_ACT_DIR, \"| parquet:\", count_parquet(STRUCT_ACT_DIR))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}